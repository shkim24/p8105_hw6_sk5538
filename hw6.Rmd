---
title: "hw6"
author: "Senna"
date: "2024-11-30"
output: github_document
---

Necessary packages are loaded.
```{r, message = FALSE, warning = FALSE}
library(tidyverse)
library(broom)
library(ggplot2)
library(purrr)
library(modelr)
library(rsample)

set.seed(123)
```



## Problem 1
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

```{r}
boot_weather = weather_df |> 
  bootstrap(n = 5000) |> 
  mutate(
    models = map(strap, \(df) lm(tmax ~ tmin, data = df)),
    glance_results = map(models, broom::glance),
    tidy_results = map(models, broom::tidy)
  ) |> 
  select(-strap, -models) |> 
  unnest(cols = c(glance_results, tidy_results), names_sep = "_") 


boot_weather|> 
  summarize(
    r_squared_mean = mean(glance_results_r.squared, na.rm = TRUE),
    r_squared_lower_ci = quantile(glance_results_r.squared, 0.025, na.rm = TRUE),
    r_squared_upper_ci = quantile(glance_results_r.squared, 0.975, na.rm = TRUE),
    log_product = ifelse(
      all(c("(Intercept)", "tmin") %in% tidy_results_term),
      tidy_results_estimate[tidy_results_term == "(Intercept)"] * 
      tidy_results_estimate[tidy_results_term == "tmin"],
      NA_real_
    ),
    log_product_mean = mean(log(log_product), na.rm = TRUE),
    log_product_lower_ci = quantile(log(log_product), 0.025, na.rm = TRUE),
    log_product_upper_ci = quantile(log(log_product), 0.975, na.rm = TRUE)
  )|>
   knitr::kable(
    format = "pipe",
    caption = "Summary of Regression Model Statistics"
  )

```


```{r}
boot_results = boot_weather|>
  filter(tidy_results_term %in% c("(Intercept)", "tmin")) |> 
  group_by(glance_results_r.squared) |> 
  summarize(
    r_squared = glance_results_r.squared,
    log_product = log(
      tidy_results_estimate[tidy_results_term == "(Intercept)"] *
      tidy_results_estimate[tidy_results_term == "tmin"]
    )
  )
```
###### r2 plot
```{r}
ggplot(boot_results, aes(x = r_squared)) +
  geom_density (color ='red', alpha = 0.5)+
  theme_minimal() +
  labs(
    title = "Distribution of R^2 from Bootstrapped Samples",
    x = expression(R^2),
    y = "Frequency"
  )
```

###### log product plot
```{r}
ggplot(boot_results, aes(x = log_product)) +
  geom_density (color ='blue', alpha = 0.5)+
  theme_minimal() +
  labs(
    title = "Distribution of log(β^0 ∗ β^1) from Bootstrapped Samples",
    x = expression(log(beta^0 * beta^1)),
    y = "Frequency"
  )
```

The log product follows a normal distribution. We had n=5000 for bootstrapping, which is a large sample size. This invokes the Central Limit Theorem.

r^2 plot shows a left skew. r^2 values are bounded between 0 and 1, and in our case, the estimate is close to 1. 

## Problem 2

```{r}
homicide_df = read.csv("./data/homicide-data.csv")|>
  mutate(
    city_state = paste(city, state, sep=","),
    solved = if_else(disposition == "Closed by arrest",1,0),
    victim_age = as.numeric(victim_age),
    victim_sex = as.factor(victim_sex),
    victim_race = as.factor(victim_race),
    solved = as.factor(solved)
  )

filtered = homicide_df|>
  filter(
    !city_state %in% c("Dallas,TX", "Phoenix,AZ", "Kansas City,MO", "Tulsa,AL"),
    victim_race %in% c("White", "Black"),
    !is.na(victim_age)
  )
```

```{r}
baltimore_df = filtered |>
  filter(city_state == "Baltimore,MD")

baltimore_model = glm(
  solved ~ victim_age + victim_sex + victim_race,
  family = binomial,
  data = baltimore_df
)

baltimore_results = tidy(baltimore_model, conf.int = TRUE, exp = TRUE)

sex_diff = baltimore_results|>
  filter (term == "victim_sexMale")|>
  select(estimate = estimate, conf.low, conf.high)

sex_diff|>
   knitr::kable(
    format = "pipe"
  )
```


```{r}
city_model = filtered|>
  group_by(city_state)|>
  nest()|>
  mutate(
    model = map(data, ~glm(solved ~ victim_age + victim_sex + victim_race, family = binomial, data = .x)),
    results = map(model, ~tidy(.x, conf.int = TRUE, exp = TRUE))
  )|>
  unnest(results)|>
  filter(term == "victim_sexMale")|>
  select(city_state, estimate = estimate, conf.low, conf.high)

city_model|>
   knitr::kable(
    format = "pipe"
  )
```

```{r}
ordered_results = city_model|> arrange(estimate)

ggplot(ordered_results, aes(x= reorder(city_state, estimate), y = estimate))+
  geom_point()+
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high))+
  labs(
    title = "adjusted odds ratio for solved homicides",
    x = "city",
    y = "adjusted odds ratio: male vs female"
  )+
  theme(
    axis.text.x = element_text(angle = 90, hjust = 1)  
  )
```
An adjusted odds ratio greater than 1 indicates that male victims are more likely to have their homicides solved compared to female victims. The adjusted odds ratios vary across cities. Cities with the error bars not crossing 1 suggest a significant difference in male and female victims' homicide being solved. If the error bar crosses 1, there is no significant difference.

For instance, cities such as New York, San Antonio, Detroit and more show that female victims are more likely to have their homicides solved. 
Cities such as Philadelphia and Atlanta show no signicifant difference. None of the cities show that male victims are more likley to have their homicides solved. 

## Problem 3

```{r}
bw_df = read.csv("./data/birthweight.csv")|>
  mutate(
    babysex = factor(babysex, labels = c("Male", "Female")),
    frace = factor(frace, levels = c(1, 2, 3, 4, 8, 9), 
                   labels = c("White", "Black", "Asian", "Puerto Rican", "Other", "Unknown")),
    mrace = factor(mrace, levels = c(1, 2, 3, 4, 8), 
                   labels = c("White", "Black", "Asian", "Puerto Rican", "Other")),
    malform = factor(malform, levels = c(0, 1), labels = c("Absent", "Present"))
  )

```

Mother’s age, gestational age, mother’s pre-pregnancy BMI, mother’s weight gain, and father’s income are retained in my model because they are strong, well-established predictors of birthweight.  

Father’s and mother’s race are also included to account for socioeconomic and healthcare access differences. Father's race and income could be related, therefore I will add them as an interaction term.  

Malformation is included because they directly affect birthweight by influencing fetal development.

```{r}
bwt_model <- lm(bwt ~  delwt + momage + gaweeks + ppbmi + wtgain + fincome*frace  + mrace + malform,  data = bw_df)

summary(bwt_model)

```
```{r}
bw_df = bw_df |>
  add_predictions(bwt_model)|>
  add_residuals(bwt_model)

ggplot(bw_df, aes(x=pred, y=resid))+
  geom_point()+
  geom_hline(yintercept=0, linetype = 'dashed')+
  labs(
    title = "residuals vs fitted values",
    x = "predicted birth weight (fitted)",
    y = "residuals"
  )
```

The two models being compared to my proposed model are denoted as model2 and model3 respectively in the code below. 

```{r}
cv_df = 
  crossv_mc(bw_df, 100)

cv_df =cv_df |> 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))
```

```{r}
cv_df = cv_df |> 
  mutate(
    model1  = map(train, \(df) lm(bwt ~ babysex + delwt + momage + gaweeks + ppbmi + wtgain + fincome + frace + mrace + malform, data = df)),
    model2  = map(train, \(df) lm(bwt ~ blength + gaweeks, data = df)),
    model3  = map(train, \(df) lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead * blength * babysex, data = df))) |> 
  mutate(
    rmse_1 = map2_dbl(model1, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_2 = map2_dbl(model2, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_3 = map2_dbl(model3, test, \(mod, df) rmse(model = mod, data = df)))
```

```{r}
cv_df |> 
  select(starts_with("rmse")) |> 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") |> 
  mutate(model = fct_inorder(model)) |> 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```
The violin for model 1 (my proposed model) is wider and is at the higher end of the RMSE range. This indicates a higher variance in the RMSE values and that the predictions are less consistent.

Model 3 performs better than model 1 and 2 since its violin is at the lower RMSE values with less variance. 

Overall, model 3 performs the best out of the three, with model 2 outperforming model 1. 






